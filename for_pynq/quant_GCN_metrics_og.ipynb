{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddde9df-4f5e-46ec-9a39-4b8884830cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx \n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from brevitas.nn import QuantLinear, QuantReLU, QuantIdentity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5633b153-6c1e-4d15-802d-d76e4d7dd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c25c65c5-14fc-46ca-b6a6-20a3d7c7a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import FacebookPagePage\n",
    "from torch_geometric.utils import degree, to_dense_adj\n",
    "from torch_geometric.transforms import GCNNorm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2f3e7c-2624-4720-acde-342f8988dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='.', name = 'Cora')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc204dba-a4ff-4cc9-9136-f85b9a096f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FacebookPagePage()\n",
      "-----------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 22470\n",
      "Number of features: 128\n",
      "Number of classes: 4\n",
      "\n",
      "Graph:\n",
      "------\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: True\n"
     ]
    }
   ],
   "source": [
    "# Import dataset from PyTorch Geometric\n",
    "dataset = FacebookPagePage(root=\".\")\n",
    "\n",
    "data = dataset[0]\n",
    "\n",
    "# Print information about the dataset\n",
    "print(f'Dataset: {dataset}')\n",
    "print('-----------------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# Print information about the graph\n",
    "print(f'\\nGraph:')\n",
    "print('------')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')\n",
    "\n",
    "# Create masks\n",
    "data.train_mask = range(18000)\n",
    "data.val_mask = range(18001, 20000)\n",
    "data.test_mask = range(20001, 22470)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1927c76-37b1-4955-b74c-ae49957989f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = degree(data.edge_index[0]).numpy()\n",
    "numbers = Counter(degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa3ff1-3e42-4669-9f5c-cbc4cff201bc",
   "metadata": {},
   "source": [
    "## Now we define our GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99fca57f-2ffa-4255-972e-ee1c1df9601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f40936df-1a3c-4f9e-bdb7-7b0c7a207857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "norm_edge_index, norm_edge_weight = gcn_norm(\n",
    "    edge_index=data.edge_index,\n",
    "    edge_weight=None, # Assuming unweighted graph initially\n",
    "    num_nodes=data.num_nodes,\n",
    "    improved=False,\n",
    "    add_self_loops=True,\n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f29da0c0-1777-4f42-b577-5aabef06b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "# This uses norm_edge_index and norm_edge_weight from your gcn_norm() call\n",
    "sparse_adj = SparseTensor.from_edge_index(\n",
    "    norm_edge_index,\n",
    "    norm_edge_weight,\n",
    "    sparse_sizes=(data.num_nodes, data.num_nodes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e6a71e3-91c0-4dac-80bc-ffa5883fe659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantGCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, weight_bit_width=8, act_bit_width=8, bias=True, bias_quantizer=False, return_quant_tensor=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "    # Quantized linear layer for X * W\n",
    "        self.linear = QuantLinear(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "            bias=bias,\n",
    "            weight_bit_width=weight_bit_width,\n",
    "            bias_quantizer=bias_quantizer, # Pass bias quantizer if you define one\n",
    "            return_quant_tensor=return_quant_tensor\n",
    "        )\n",
    "\n",
    "    def forward(self, x, sparse_norm_adj):\n",
    "        # 1. Linear transformation (X * W_quant)\n",
    "        # If x is float, QuantLinear quantizes it first internally based on its input_quantizer.\n",
    "        # If x is QuantTensor, QuantLinear uses its scale.\n",
    "        transformed_features = self.linear(x) # Output is a QuantTensor if return_quant_tensor=True\n",
    "\n",
    "        # 2. Graph propagation ((D^-1/2 * A_hat * D^-1/2) * XW)\n",
    "        # torch.mm can handle if one input is QuantTensor and other is float.\n",
    "        # The output will be a QuantTensor preserving the scale from transformed_features.\n",
    "        output_features = sparse_norm_adj.matmul(transformed_features.tensor)\n",
    "\n",
    "        return output_features\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}({self.in_features} -> {self.out_features})'       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ec0f1be-62f6-49d3-b9f7-6e9c371fbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.quant.scaled_int import Int8Bias\n",
    "class QuantGCN(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out,\n",
    "                 weight_bit_width=8, act_bit_width=8, in_bit_width=8,\n",
    "                 bias_quantizer=Int8Bias,\n",
    "                 mode = 'train'): # Define if you want specific bias quantization\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        # Input quantizer for the raw node features 'x'\n",
    "        self.input_quant = QuantIdentity(\n",
    "            bit_width=in_bit_width,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "\n",
    "        # First GCN layer\n",
    "        self.conv1 = QuantGCNLayer(\n",
    "            dim_in, dim_h,\n",
    "            weight_bit_width=weight_bit_width,\n",
    "            bias=True, # Standard GCNConv has bias\n",
    "            bias_quantizer=bias_quantizer,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "\n",
    "        # Quantized ReLU activation\n",
    "        self.relu1 = QuantReLU(\n",
    "            bit_width=act_bit_width,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "\n",
    "                # First GCN layer\n",
    "        self.conv2 = QuantGCNLayer(\n",
    "            dim_h, dim_out,\n",
    "            weight_bit_width=weight_bit_width,\n",
    "            bias=True, # Standard GCNConv has bias\n",
    "            bias_quantizer=bias_quantizer,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "\n",
    "        self.output_dequant = QuantIdentity(\n",
    "            return_quant_tensor=False # Returns a float torch.Tensor\n",
    "        )\n",
    "        self.output_quant = QuantIdentity(\n",
    "        return_quant_tensor=True # Returns a QuantReLU tensor\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, dense_norm_adj):\n",
    "        \"\"\"\n",
    "        x: Raw node features, shape (num_nodes, dim_in)\n",
    "        dense_norm_adj: Pre-computed dense normalized adjacency matrix,\n",
    "                        shape (num_nodes, num_nodes)\n",
    "        \"\"\"\n",
    "        # 1. Quantize input features\n",
    "        x_quant = self.input_quant(x)\n",
    "\n",
    "        # 2. First GCN layer + ReLU\n",
    "        h1 = self.conv1(x_quant, dense_norm_adj)\n",
    "        h1_activated = self.relu1(h1)\n",
    "\n",
    "        # 3. Second GCN layer\n",
    "        h2 = self.conv2(h1_activated, dense_norm_adj)\n",
    "        \n",
    "        # 4. Dequantize output for training loss calculation\n",
    "        mode = self.mode\n",
    "        final_logits = self.output_dequant(h2)\n",
    "        export_logits = self.output_quant(h2)\n",
    "        # For comparison with a PyG GCN model that uses F.log_softmax:\n",
    "        if (mode=='train'):\n",
    "            return F.log_softmax(final_logits, dim=1)\n",
    "        # For training with CrossEntropyLoss and for FINN (which prefers logits):\n",
    "        else:\n",
    "            \n",
    "            return export_logits\n",
    "            #return final_logits\n",
    "\n",
    "    def fit(self, data, dense_norm_adj, epochs, lr=0.001, weight_decay=5e-4):\n",
    "        # Ensure data.y is prepared (e.g., torch.long, correct device)\n",
    "        # Ensure dense_norm_adj is on the correct device\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Ensure features and adjacency are on the same device as the model\n",
    "            features = data.x.to(next(self.parameters()).device)\n",
    "            adj = dense_norm_adj.to(next(self.parameters()).device)\n",
    "            \n",
    "            out = self(features, adj)\n",
    "            \n",
    "            train_mask_device = data.train_mask\n",
    "            labels_device = data.y\n",
    "\n",
    "            loss = criterion(out[train_mask_device], labels_device[train_mask_device])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
    "                          data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if(epoch % 20 == 0):\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
    "                                  data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
    "                      f' {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                      f'Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, data, dense_norm_adj):\n",
    "        self.eval()\n",
    "        mode = self.mode\n",
    "        print(mode)\n",
    "        features = data.x.to(next(self.parameters()).device)\n",
    "        adj = dense_norm_adj.to(next(self.parameters()).device)\n",
    "        out = self(features, adj)\n",
    "        if (mode =='train'):\n",
    "            out = out\n",
    "        else:\n",
    "            out = out.tensor\n",
    "        test_mask_device = data.test_mask\n",
    "        labels_device = data.y\n",
    "        acc = accuracy(out.argmax(dim=1)[test_mask_device], labels_device[test_mask_device])\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e47cdae-d060-4129-847e-39b7223a1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 8\n",
    "a = 8\n",
    "wa = 'w8a8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32a5f5e2-da67-4a1b-bc8e-5ce8f348822e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantGCN(\n",
      "  (input_quant): QuantIdentity(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv1): QuantGCNLayer(128 -> 64)\n",
      "  (relu1): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): QuantGCNLayer(64 -> 4)\n",
      "  (output_dequant): QuantIdentity(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_quant): QuantIdentity(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "quant_gcn = QuantGCN(dataset.num_features, 64, dataset.num_classes, weight_bit_width=w, act_bit_width=a, in_bit_width=32, mode='train')\n",
    "print(quant_gcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1c97132-b00f-44e6-8686-7353d6f49d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.392 | Train Acc: 21.88% | Val Loss: 1.39 | Val Acc: 22.86%\n",
      "Epoch  20 | Train Loss: 0.488 | Train Acc: 83.22% | Val Loss: 0.49 | Val Acc: 83.64%\n",
      "Epoch  40 | Train Loss: 0.322 | Train Acc: 89.74% | Val Loss: 0.31 | Val Acc: 89.74%\n",
      "Epoch  60 | Train Loss: 0.274 | Train Acc: 91.44% | Val Loss: 0.27 | Val Acc: 91.70%\n",
      "Epoch  80 | Train Loss: 0.251 | Train Acc: 92.47% | Val Loss: 0.25 | Val Acc: 92.70%\n",
      "Epoch 100 | Train Loss: 0.235 | Train Acc: 93.10% | Val Loss: 0.24 | Val Acc: 93.15%\n",
      "Epoch 120 | Train Loss: 0.223 | Train Acc: 93.50% | Val Loss: 0.23 | Val Acc: 93.45%\n",
      "Epoch 140 | Train Loss: 0.214 | Train Acc: 93.83% | Val Loss: 0.22 | Val Acc: 93.50%\n",
      "Epoch 160 | Train Loss: 0.204 | Train Acc: 94.14% | Val Loss: 0.22 | Val Acc: 93.55%\n",
      "Epoch 180 | Train Loss: 0.197 | Train Acc: 94.33% | Val Loss: 0.21 | Val Acc: 93.60%\n",
      "Epoch 200 | Train Loss: 0.190 | Train Acc: 94.60% | Val Loss: 0.21 | Val Acc: 93.70%\n",
      "Epoch 220 | Train Loss: 0.184 | Train Acc: 94.78% | Val Loss: 0.20 | Val Acc: 93.75%\n",
      "Epoch 240 | Train Loss: 0.178 | Train Acc: 94.97% | Val Loss: 0.20 | Val Acc: 94.00%\n",
      "Epoch 260 | Train Loss: 0.173 | Train Acc: 95.17% | Val Loss: 0.20 | Val Acc: 93.80%\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "quant_gcn.fit(data,sparse_adj, epochs=260, lr = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0afb856c-c4e2-40cf-ad7d-84d1fff4e6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "\n",
      "GCN test accuracy: 93.60%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "acc = quant_gcn.test(data, sparse_adj)\n",
    "print(f'\\nGCN test accuracy: {acc*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffb80f3d-6756-4c3f-82c4-d337963eb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = f'quant_gcn_trained_weights_{wa}.pth'\n",
    "torch.save(quant_gcn.state_dict(), export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aca5e440-508d-468c-9cd6-f68b5f15f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_gcn_export = QuantGCN(dataset.num_features, 64, dataset.num_classes, weight_bit_width=w, act_bit_width=a, in_bit_width=32, mode='export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb34a91d-f032-440c-85b7-0a147830f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights = torch.load(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee43a0a1-2884-4dcc-8177-db1fae5158b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_gcn_export.load_state_dict(trained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0812383e-6960-4dca-b0e0-8f5d6257bf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export\n",
      "\n",
      "GCN test accuracy for w8a8: 93.60%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc2 = quant_gcn_export.test(data, sparse_adj)\n",
    "print(f'\\nGCN test accuracy for {wa}: {acc2*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510d6d8-f90e-4007-b423-b9de2a11b32a",
   "metadata": {},
   "source": [
    "## now to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2353335-1e03-47c2-885f-33c2de1d44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_np = data.x.numpy().astype(np.float32)\n",
    "norm_edge_index, norm_edge_weight = gcn_norm(\n",
    "    edge_index=data.edge_index,\n",
    "    edge_weight=None,\n",
    "    num_nodes=data.num_nodes,\n",
    "    improved=False,\n",
    "    add_self_loops=True,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "edge_index_np = norm_edge_index.numpy().astype(np.int64)\n",
    "edge_weight_np = norm_edge_weight.numpy().astype(np.float32)\n",
    "\n",
    "feat_np = np.ascontiguousarray(feat_np)\n",
    "edge_index_np = np.ascontiguousarray(edge_index_np)\n",
    "edge_weight_np = np.ascontiguousarray(edge_weight_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dacd768-d7eb-47aa-814b-898f0eaae3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features.npy', feat_np)\n",
    "np.save('edge_index.npy', edge_index_np)\n",
    "np.save('edge_weight.npy', edge_weight_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdaef5b4-771a-47b4-b619-0932e020666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8179bd5-4e4a-483a-8d4f-3b4877848161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanGCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, bias=True):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats, bias=bias)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        return adj @ self.linear(x)\n",
    "\n",
    "class CleanGCN(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = CleanGCNLayer(dim_in, dim_h)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = CleanGCNLayer(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.relu1(self.conv1(x, adj))\n",
    "        return self.conv2(h, adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34f75466-b5c3-49cc-91cb-d945c52f4e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CleanGCN(\n",
       "  (conv1): CleanGCNLayer(\n",
       "    (linear): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (relu1): ReLU()\n",
       "  (conv2): CleanGCNLayer(\n",
       "    (linear): Linear(in_features=64, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brevitas_weights = torch.load(f'quant_gcn_trained_weights_{wa}.pth', map_location='cpu')\n",
    "\n",
    "# Mapping to clean model\n",
    "mapped_weights = {\n",
    "    'conv1.linear.weight': brevitas_weights['conv1.linear.weight'],\n",
    "    'conv1.linear.bias':   brevitas_weights['conv1.linear.bias'],\n",
    "    'conv2.linear.weight': brevitas_weights['conv2.linear.weight'],\n",
    "    'conv2.linear.bias':   brevitas_weights['conv2.linear.bias'],\n",
    "}\n",
    "\n",
    "clean_model = CleanGCN(dim_in=dataset.num_features, dim_h=64, dim_out=dataset.num_classes)\n",
    "clean_model.load_state_dict(mapped_weights)\n",
    "clean_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45329f9e-5c67-4520-8377-2990e3dd2b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to clean_gcn_export_w8a8.onnx\n"
     ]
    }
   ],
   "source": [
    "dummy_x = torch.randn(data.num_nodes, dataset.num_features, dtype=torch.float32)\n",
    "dummy_adj = torch.randn(data.num_nodes, data.num_nodes, dtype=torch.float32)\n",
    "\n",
    "torch.onnx.export(\n",
    "    clean_model,\n",
    "    (dummy_x, dummy_adj),\n",
    "    f\"clean_gcn_export_{wa}.onnx\",\n",
    "    input_names=['global_in', 'global_in_1'],\n",
    "    output_names=['global_out'],\n",
    "    opset_version=13\n",
    ")\n",
    "print(f'Exported to clean_gcn_export_{wa}.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b5d91-ebe9-4e0e-8ef5-dcd89d56909d",
   "metadata": {},
   "source": [
    "# now move to the fpga and get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb7929-a61a-4f9b-a79f-b830c7cdd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "# Load your FPGA output (logits)\n",
    "fpga_output = np.load(f'fpga_output_{wa}.npy')  # shape: (2708, num_classes)\n",
    "\n",
    "# Convert logits to predictions (class with highest score)\n",
    "preds = np.argmax(fpga_output, axis=1)\n",
    "\n",
    "# Load true labels from the dataset\n",
    "dataset = Planetoid(root=\"data/Cora\", name=\"Cora\")\n",
    "true_labels = dataset[0].y.numpy()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, preds)\n",
    "print(f\"Accuracy on FPGA output for {wa}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(true_labels, preds, digits=4)\n",
    "print(f\"Classification Report for {wa}:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb003eb-6fee-4587-81ab-779639bc05dc",
   "metadata": {},
   "source": [
    "## Now we generate graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7818c4-a60f-4a8b-b504-f0a8352b6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Set style for publication-quality plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Your experimental data\n",
    "quantization_levels = ['W32A32', 'W16A16', 'W8A8', 'W4A4', 'W2A2']\n",
    "bit_widths = [32, 16, 8, 4, 2]\n",
    "\n",
    "# Training accuracies (from your results)\n",
    "training_accuracy = [80.9, 80.90, 81.00, 80.90, 75.10]\n",
    "\n",
    "# FPGA accuracies (from your results)\n",
    "fpga_accuracy = [80.9, 79.95, 79.87, 79.95, 74.85]  # Assuming W32A32 same as training\n",
    "\n",
    "# Runtime data (seconds)\n",
    "runtime = [2.5, 2.5408, 2.4667, 2.0962, 2.4624]  # Estimated W32A32\n",
    "\n",
    "# Throughput (nodes/sec)\n",
    "throughput = [1065, 1065.79, 1097.82, 1291.87, 1099.72]  # Estimated W32A32\n",
    "\n",
    "# Power estimation (ARM core 400mW)\n",
    "power_consumption = 0.4  # Watts\n",
    "energy_consumption = [power_consumption * t for t in runtime]  # Joules\n",
    "\n",
    "# Classification metrics (from your classification reports)\n",
    "# You'll need to extract these from your sklearn classification reports\n",
    "precision_scores = {\n",
    "    'W32A32': [0.68, 0.76, 0.86, 0.89, 0.76, 0.85, 0.66],  # Estimated based on pattern\n",
    "    'W16A16': [0.6831, 0.7550, 0.8638, 0.8882, 0.7631, 0.8500, 0.6623],\n",
    "    'W8A8': [0.6849, 0.7550, 0.8638, 0.8879, 0.7615, 0.8500, 0.6565],\n",
    "    'W4A4': [0.6510, 0.7602, 0.8509, 0.8841, 0.8041, 0.8340, 0.6901],\n",
    "    'W2A2': [0.6842, 0.7830, 0.5787, 0.9257, 0.7817, 0.9202, 0.7026]\n",
    "}\n",
    "\n",
    "recall_scores = {\n",
    "    'W32A32': [0.71, 0.86, 0.93, 0.74, 0.85, 0.74, 0.84],  # Estimated\n",
    "    'W16A16': [0.7123, 0.8664, 0.9258, 0.7384, 0.8545, 0.7416, 0.8389],\n",
    "    'W8A8': [0.7123, 0.8664, 0.9258, 0.7359, 0.8545, 0.7416, 0.8389],\n",
    "    'W4A4': [0.7493, 0.8618, 0.9282, 0.7457, 0.8192, 0.7416, 0.8167],\n",
    "    'W2A2': [0.7407, 0.7650, 0.9856, 0.6088, 0.8404, 0.6577, 0.7611]\n",
    "}\n",
    "\n",
    "f1_scores = {\n",
    "    'W32A32': [0.69, 0.81, 0.89, 0.81, 0.80, 0.79, 0.74],  # Estimated\n",
    "    'W16A16': [0.6974, 0.8069, 0.8938, 0.8064, 0.8062, 0.7921, 0.7402],\n",
    "    'W8A8': [0.6983, 0.8069, 0.8938, 0.8048, 0.8053, 0.7921, 0.7366],\n",
    "    'W4A4': [0.6967, 0.8078, 0.8879, 0.8090, 0.8116, 0.7851, 0.7481],\n",
    "    'W2A2': [0.7114, 0.7739, 0.7292, 0.7345, 0.8100, 0.7671, 0.7307]\n",
    "}\n",
    "\n",
    "# Calculate macro averages\n",
    "macro_precision = [np.mean(precision_scores[level]) for level in quantization_levels]\n",
    "macro_recall = [np.mean(recall_scores[level]) for level in quantization_levels]\n",
    "macro_f1 = [np.mean(f1_scores[level]) for level in quantization_levels]\n",
    "\n",
    "def create_accuracy_comparison_plot():\n",
    "    \"\"\"Plot training vs FPGA accuracy comparison\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    x = np.arange(len(quantization_levels))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, training_accuracy, width, label='Training Accuracy', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, fpga_accuracy, width, label='FPGA Accuracy', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Quantization Level', fontsize=12)\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax.set_title('GCN Accuracy: Training vs FPGA Deployment', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(quantization_levels)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(70, 85)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.1f}%',\n",
    "                       xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                       xytext=(0, 3),\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def create_performance_metrics_plot():\n",
    "    \"\"\"Plot performance metrics (throughput, energy, runtime)\"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Throughput plot\n",
    "    bars1 = ax1.bar(quantization_levels, throughput, color='skyblue', alpha=0.8)\n",
    "    ax1.set_ylabel('Throughput (nodes/sec)', fontsize=12)\n",
    "    ax1.set_title('Throughput vs Quantization Level', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    for bar, val in zip(bars1, throughput):\n",
    "        ax1.annotate(f'{val:.0f}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    \n",
    "    # Energy consumption plot\n",
    "    bars2 = ax2.bar(quantization_levels, energy_consumption, color='lightcoral', alpha=0.8)\n",
    "    ax2.set_ylabel('Energy Consumption (Joules)', fontsize=12)\n",
    "    ax2.set_title('Energy Consumption vs Quantization Level', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    for bar, val in zip(bars2, energy_consumption):\n",
    "        ax2.annotate(f'{val:.2f}J', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    \n",
    "    # Runtime plot\n",
    "    bars3 = ax3.bar(quantization_levels, runtime, color='lightgreen', alpha=0.8)\n",
    "    ax3.set_ylabel('Runtime (seconds)', fontsize=12)\n",
    "    ax3.set_title('Runtime vs Quantization Level', fontsize=12, fontweight='bold')\n",
    "    ax3.set_xlabel('Quantization Level', fontsize=12)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    for bar, val in zip(bars3, runtime):\n",
    "        ax3.annotate(f'{val:.2f}s', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    \n",
    "    # Energy efficiency (throughput/energy)\n",
    "    energy_efficiency = [t/e for t, e in zip(throughput, energy_consumption)]\n",
    "    bars4 = ax4.bar(quantization_levels, energy_efficiency, color='gold', alpha=0.8)\n",
    "    ax4.set_ylabel('Energy Efficiency (nodes/Joule)', fontsize=12)\n",
    "    ax4.set_title('Energy Efficiency vs Quantization Level', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xlabel('Quantization Level', fontsize=12)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    for bar, val in zip(bars4, energy_efficiency):\n",
    "        ax4.annotate(f'{val:.0f}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def create_classification_metrics_plot():\n",
    "    \"\"\"Plot precision, recall, F1-score\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    \n",
    "    x = np.arange(len(quantization_levels))\n",
    "    width = 0.25\n",
    "    \n",
    "    bars1 = ax.bar(x - width, macro_precision, width, label='Precision', alpha=0.8)\n",
    "    bars2 = ax.bar(x, macro_recall, width, label='Recall', alpha=0.8)\n",
    "    bars3 = ax.bar(x + width, macro_f1, width, label='F1-Score', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Quantization Level', fontsize=12)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title('Classification Metrics vs Quantization Level', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(quantization_levels)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0.65, 0.85)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bars in [bars1, bars2, bars3]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.3f}',\n",
    "                       xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                       xytext=(0, 3),\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def create_bit_width_analysis():\n",
    "    \"\"\"Plot metrics vs bit width for trend analysis\"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Accuracy vs bit width\n",
    "    ax1.plot(bit_widths, fpga_accuracy, 'o-', linewidth=2, markersize=8, label='FPGA Accuracy')\n",
    "    ax1.set_xlabel('Bit Width', fontsize=12)\n",
    "    ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax1.set_title('Accuracy Degradation vs Bit Width', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xscale('log', base=2)\n",
    "    ax1.set_xticks(bit_widths)\n",
    "    ax1.set_xticklabels(bit_widths)\n",
    "    \n",
    "    # Throughput vs bit width\n",
    "    ax2.plot(bit_widths, throughput, 's-', linewidth=2, markersize=8, color='orange', label='Throughput')\n",
    "    ax2.set_xlabel('Bit Width', fontsize=12)\n",
    "    ax2.set_ylabel('Throughput (nodes/sec)', fontsize=12)\n",
    "    ax2.set_title('Throughput vs Bit Width', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xscale('log', base=2)\n",
    "    ax2.set_xticks(bit_widths)\n",
    "    ax2.set_xticklabels(bit_widths)\n",
    "    \n",
    "    # Energy efficiency vs bit width\n",
    "    energy_efficiency = [t/e for t, e in zip(throughput, energy_consumption)]\n",
    "    ax3.plot(bit_widths, energy_efficiency, '^-', linewidth=2, markersize=8, color='green', label='Energy Efficiency')\n",
    "    ax3.set_xlabel('Bit Width', fontsize=12)\n",
    "    ax3.set_ylabel('Energy Efficiency (nodes/Joule)', fontsize=12)\n",
    "    ax3.set_title('Energy Efficiency vs Bit Width', fontsize=12, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_xscale('log', base=2)\n",
    "    ax3.set_xticks(bit_widths)\n",
    "    ax3.set_xticklabels(bit_widths)\n",
    "    \n",
    "    # Combined metrics (normalized)\n",
    "    norm_accuracy = np.array(fpga_accuracy) / max(fpga_accuracy)\n",
    "    norm_throughput = np.array(throughput) / max(throughput)\n",
    "    norm_efficiency = np.array(energy_efficiency) / max(energy_efficiency)\n",
    "    \n",
    "    ax4.plot(bit_widths, norm_accuracy, 'o-', linewidth=2, markersize=6, label='Accuracy (norm)')\n",
    "    ax4.plot(bit_widths, norm_throughput, 's-', linewidth=2, markersize=6, label='Throughput (norm)')\n",
    "    ax4.plot(bit_widths, norm_efficiency, '^-', linewidth=2, markersize=6, label='Energy Eff. (norm)')\n",
    "    ax4.set_xlabel('Bit Width', fontsize=12)\n",
    "    ax4.set_ylabel('Normalized Score', fontsize=12)\n",
    "    ax4.set_title('Normalized Metrics vs Bit Width', fontsize=12, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_xscale('log', base=2)\n",
    "    ax4.set_xticks(bit_widths)\n",
    "    ax4.set_xticklabels(bit_widths)\n",
    "    ax4.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def create_summary_table():\n",
    "    \"\"\"Create a summary table of all results\"\"\"\n",
    "    data = {\n",
    "        'Quantization': quantization_levels,\n",
    "        'Training Acc (%)': training_accuracy,\n",
    "        'FPGA Acc (%)': fpga_accuracy,\n",
    "        'Precision': [f\"{p:.3f}\" for p in macro_precision],\n",
    "        'Recall': [f\"{r:.3f}\" for r in macro_recall],\n",
    "        'F1-Score': [f\"{f:.3f}\" for f in macro_f1],\n",
    "        'Runtime (s)': [f\"{r:.2f}\" for r in runtime],\n",
    "        'Throughput (nodes/s)': [f\"{t:.0f}\" for t in throughput],\n",
    "        'Energy (J)': [f\"{e:.2f}\" for e in energy_consumption],\n",
    "        'Energy Eff (nodes/J)': [f\"{t/e:.0f}\" for t, e in zip(throughput, energy_consumption)]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.5)\n",
    "    \n",
    "    # Style the table\n",
    "    for i in range(len(df.columns)):\n",
    "        table[(0, i)].set_facecolor('#40466e')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    plt.title('GCN Quantization Results Summary', fontsize=16, fontweight='bold', pad=20)\n",
    "    return fig\n",
    "\n",
    "# Function to load and analyze classification report from npy file\n",
    "def analyze_classification_report_from_npy(npy_file_path, true_labels_file=None):\n",
    "    \"\"\"\n",
    "    Analyze classification results from numpy files\n",
    "    \n",
    "    Args:\n",
    "        npy_file_path: Path to .npy file containing predictions\n",
    "        true_labels_file: Path to true labels (if separate file)\n",
    "    \"\"\"\n",
    "    predictions = np.load(npy_file_path)\n",
    "    \n",
    "    if true_labels_file:\n",
    "        true_labels = np.load(true_labels_file)\n",
    "    else:\n",
    "        # You'll need to provide true labels somehow\n",
    "        print(\"Please provide true labels for classification report generation\")\n",
    "        return None\n",
    "    \n",
    "    from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(true_labels, predictions, output_dict=True)\n",
    "    \n",
    "    # Extract metrics\n",
    "    precision = [report[str(i)]['precision'] for i in range(len(report)-3)]\n",
    "    recall = [report[str(i)]['recall'] for i in range(len(report)-3)]\n",
    "    f1 = [report[str(i)]['f1-score'] for i in range(len(report)-3)]\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create all plots\n",
    "    print(\"Generating GCN quantization analysis plots...\")\n",
    "    \n",
    "    # Generate plots\n",
    "    fig1 = create_accuracy_comparison_plot()\n",
    "    fig1.savefig('gcn_accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    fig2 = create_performance_metrics_plot()\n",
    "    fig2.savefig('gcn_performance_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    fig3 = create_classification_metrics_plot()\n",
    "    fig3.savefig('gcn_classification_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    fig4 = create_bit_width_analysis()\n",
    "    fig4.savefig('gcn_bit_width_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    fig5 = create_summary_table()\n",
    "    fig5.savefig('gcn_results_summary.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(\"All plots saved successfully!\")\n",
    "    print(\"Files generated:\")\n",
    "    print(\"- gcn_accuracy_comparison.png\")\n",
    "    print(\"- gcn_performance_metrics.png\") \n",
    "    print(\"- gcn_classification_metrics.png\")\n",
    "    print(\"- gcn_bit_width_analysis.png\")\n",
    "    print(\"- gcn_results_summary.png\")\n",
    "    \n",
    "    # Show plots\n",
    "    plt.show()\n",
    "\n",
    "# Additional utility function for custom analysis\n",
    "def custom_analysis_from_your_data(your_npy_predictions, your_true_labels):\n",
    "    \"\"\"\n",
    "    Use this function with your actual .npy files\n",
    "    Replace the estimated data above with real data from your files\n",
    "    \"\"\"\n",
    "    # Load your data\n",
    "    predictions = np.load(your_npy_predictions)\n",
    "    labels = np.load(your_true_labels)\n",
    "    \n",
    "    # Generate metrics for each quantization level\n",
    "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=None)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Per-class Precision: {precision}\")\n",
    "    print(f\"Per-class Recall: {recall}\")\n",
    "    print(f\"Per-class F1: {f1}\")\n",
    "    \n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef49c3f-fd29-46cb-a229-2e5cebf6e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Data ---\n",
    "quant_levels = ['w16a16', 'w8a8', 'w4a4', 'w2a2']\n",
    "fpga_accuracy = np.array([79.95, 79.87, 79.95, 74.85])\n",
    "weighted_precision = np.array([0.8083, 0.8078, 0.8078, 0.7913]) * 100 # Convert to percentage for plotting alongside accuracy\n",
    "weighted_recall = np.array([0.7995, 0.7987, 0.7995, 0.7485]) * 100    # Convert to percentage\n",
    "weighted_f1_score = np.array([0.7998, 0.7991, 0.8003, 0.7490]) * 100 # Convert to percentage\n",
    "\n",
    "pc_accuracy_32bit = 80.9  # For reference\n",
    "\n",
    "runtimes = np.array([2.5408, 2.4667, 2.0962, 2.4624]) # seconds\n",
    "throughput = np.array([1065.79, 1097.82, 1291.87, 1099.72]) # nodes/sec\n",
    "\n",
    "# Estimated Energy Consumption (Joules)\n",
    "# Power = 400mW = 0.4W\n",
    "power_arm_core = 0.4 # Watts\n",
    "estimated_energy = power_arm_core * runtimes # Joules\n",
    "\n",
    "# --- Plotting Functions ---\n",
    "\n",
    "def plot_grouped_bar_chart(ax, data_dict, title, ylabel, add_reference_line=None, ref_line_label=None, y_limit=None):\n",
    "    \"\"\"Plots a grouped bar chart.\"\"\"\n",
    "    n_groups = len(quant_levels)\n",
    "    n_bars = len(data_dict)\n",
    "    bar_width = 0.8 / n_bars # Adjust bar width based on number of metrics\n",
    "    index = np.arange(n_groups)\n",
    "\n",
    "    for i, (metric_name, values) in enumerate(data_dict.items()):\n",
    "        bar_positions = index + i * bar_width - (bar_width * (n_bars -1) / 2) # Center the group\n",
    "        bars = ax.bar(bar_positions, values, bar_width, label=metric_name)\n",
    "        # Add text labels on top of bars\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2.0, yval + 0.5, f'{yval:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Quantization Level (Weights & Activations)')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(index + bar_width / n_bars - bar_width/2) # Adjust x-ticks to be centered for the group\n",
    "    ax.set_xticklabels(quant_levels)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    if y_limit:\n",
    "        ax.set_ylim(y_limit)\n",
    "    if add_reference_line is not None:\n",
    "        ax.axhline(y=add_reference_line, color='r', linestyle='--', label=ref_line_label if ref_line_label else 'Reference')\n",
    "        ax.legend() # Update legend to include reference line\n",
    "\n",
    "\n",
    "def plot_single_bar_chart(ax, values, title, ylabel, add_reference_line=None, ref_line_label=None, y_limit=None):\n",
    "    \"\"\"Plots a single metric bar chart.\"\"\"\n",
    "    index = np.arange(len(quant_levels))\n",
    "    bars = ax.bar(index, values, 0.6, label=ylabel) # Using 0.6 for bar width\n",
    "    ax.set_xlabel('Quantization Level (Weights & Activations)')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(quant_levels)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add text labels on top of bars\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2.0, yval + (0.01 * (ax.get_ylim()[1] - ax.get_ylim()[0])), f'{yval:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "\n",
    "    if y_limit:\n",
    "        ax.set_ylim(y_limit)\n",
    "    if add_reference_line is not None:\n",
    "        ax.axhline(y=add_reference_line, color='r', linestyle='--', label=ref_line_label if ref_line_label else 'Reference')\n",
    "        ax.legend()\n",
    "\n",
    "\n",
    "# --- Create Plots ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid') # Using a seaborn style for better aesthetics\n",
    "\n",
    "# 1. Performance Metrics (Accuracy, Precision, Recall, F1-Score)\n",
    "fig1, ax1 = plt.subplots(figsize=(12, 7))\n",
    "performance_data = {\n",
    "    'FPGA Accuracy (%)': fpga_accuracy,\n",
    "    'Weighted Precision (%)': weighted_precision,\n",
    "    'Weighted Recall (%)': weighted_recall,\n",
    "    'Weighted F1-Score (%)': weighted_f1_score\n",
    "}\n",
    "plot_grouped_bar_chart(ax1, performance_data,\n",
    "                       'GCN Performance Metrics on FPGA ARM Core',\n",
    "                       'Score (%)',\n",
    "                       add_reference_line=pc_accuracy_32bit,\n",
    "                       ref_line_label=f'w32a32 PC Accuracy ({pc_accuracy_32bit}%)',\n",
    "                       y_limit=[min(0, np.min(fpga_accuracy)-10), 100])\n",
    "fig1.tight_layout()\n",
    "plt.savefig('gcn_performance_metrics.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2. Throughput\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "plot_single_bar_chart(ax2, throughput,\n",
    "                      'GCN Throughput on FPGA ARM Core',\n",
    "                      'Throughput (nodes/sec)')\n",
    "fig2.tight_layout()\n",
    "plt.savefig('gcn_throughput.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 3. Estimated Energy Consumption\n",
    "fig3, ax3 = plt.subplots(figsize=(10, 6))\n",
    "plot_single_bar_chart(ax3, estimated_energy,\n",
    "                      'Estimated Energy Consumption per Run on FPGA ARM Core',\n",
    "                      'Energy (Joules)')\n",
    "fig3.tight_layout()\n",
    "plt.savefig('gcn_energy_consumption.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Graphs generated and saved as PNG files.\")\n",
    "print(f\"Estimated Energy (Joules): {dict(zip(quant_levels, estimated_energy))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eaa990-edb2-48e0-828f-4d38f3f74e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
